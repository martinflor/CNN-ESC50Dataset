{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librarie's import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "import random\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading OGG files (audio files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ogg_file(audio, max_ms = 5000, sr = 10989):\n",
    "    # Load encoded wav file\n",
    "    x, fs = audio\n",
    "    # Sampling frequency of the ADC\n",
    "    M = fs//sr\n",
    "    # Resampling the audio file from 44100 Hz to 10200\n",
    "    sig = signal.resample(x, int(len(x)/M))\n",
    "    \n",
    "    sig_len = len(sig)\n",
    "    max_len = int(sr * max_ms/1000)\n",
    "\n",
    "    if (sig_len > max_len):\n",
    "        sig = sig[:max_len]\n",
    "\n",
    "    elif (sig_len < max_len):\n",
    "        # Length of padding to add at the beginning and end of the signal\n",
    "        pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "        pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "        # Pad with 0s\n",
    "        pad_begin = np.zeros(pad_begin_len)\n",
    "        pad_end = np.zeros(pad_end_len)\n",
    "\n",
    "        sig = np.concatenate((pad_begin, sig, pad_end))\n",
    "        \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataframe with audio resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfiles = ['203 - Crackling fire', '205 - Chirping birds', '501 - Helicopter', '502 - Chainsaw', '510 - Hand saw' ]\n",
    "original_audio = np.array([[mypath + \"/\" + f for f in listdir(mypath) if isfile(join(mypath, f))] for mypath in [\"Dataset_ESC-50/\" + soundfiles[i] for i in range(len(soundfiles))]])\n",
    "audio_df = pd.DataFrame(data = original_audio.T, columns = soundfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Melspectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melspectrogram(x, Nft = 512, fs_down = 10447, Nmel = 20) :\n",
    "    \"\"\"\n",
    "    Pre : x is the resampled signal\n",
    "    Post : melspectrogram of x\n",
    "    \"\"\"\n",
    "\n",
    "    L = len(x)\n",
    "    x_crop = x[:L-L%Nft]\n",
    "    x_new = x_crop if len(x.shape)==1 else np.mean(x_crop,axis=1)\n",
    "    L_new = len(x_new)\n",
    "    \n",
    "    audiomat = np.reshape(x_new, (L_new//Nft,Nft))\n",
    "    audioham = audiomat*np.hamming(Nft) # Windowing.\n",
    "    z = np.reshape(audioham,-1) # y windowed by pieces\n",
    "\n",
    "    stft = np.fft.fft(audioham, axis=1)\n",
    "    stft = np.abs(stft[:,:Nft//2].T) # Taking only positive frequencies and computing the magnitude\n",
    "    \n",
    "    mels = librosa.filters.mel(sr=fs_down, n_fft=Nft, n_mels=Nmel)\n",
    "    mels = mels[:,:-1]\n",
    "    mels = mels/np.max(mels)\n",
    "    \n",
    "    melspec = mels@stft\n",
    "    \n",
    "    return melspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating an entire dataset from audio path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Audio transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "def time_shift(filename, shift_limit=0.4):\n",
    "    sig = load_ogg_file(sf.read(filename))\n",
    "    sig_len = len(sig)\n",
    "    shift_amt = int(random.random() * shift_limit * sig_len)\n",
    "    return np.roll(sig, shift_amt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(filename, scaling_limit=5):\n",
    "    sig = load_ogg_file(sf.read(filename))\n",
    "    sig = np.random.uniform(0,scaling_limit)*sig\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(filename, sigma=0.05):\n",
    "    sig = load_ogg_file(sf.read(filename))\n",
    "    size = len(sig)\n",
    "    random_list = np.random.normal(loc=0.0, scale=sigma, size=size)\n",
    "    return sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Dataset matching specifications\n",
    "- ADC samples the signal received from the microphone at a 10989 Hz\n",
    "- 20 melvectors are computed with ONLY 10 components (here we have 107)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shaping_audio(audio, dic, col, nb = 10, sr=10989) :\n",
    "    sig = audio\n",
    "    sig_len = sig.shape[0]\n",
    "    L = sig_len//nb\n",
    "    for i in range(nb) :\n",
    "        mels = melspectrogram(sig[i*L:(i+1)*L])\n",
    "        dic[col].append(mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shape(_df) :\n",
    "    dic = {}\n",
    "    for i in _df.columns :\n",
    "        print(i)\n",
    "        dic[i] = []\n",
    "        for sig in _df[i].values :\n",
    "            shaping_audio(sig, dic, i)\n",
    "    return pd.DataFrame.from_dict(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(paths, labels, transform = False) :\n",
    "    df = pd.DataFrame(data = paths, columns = labels) # sound paths\n",
    "    df_original = df.applymap(lambda x :  sf.read(x)) # sounds\n",
    "    df_original = data_shape(df_original.applymap(load_ogg_file)) # shaping sounds\n",
    "    \n",
    "    lst = [df_original]\n",
    "    for i in range(30) :\n",
    "        print(\"computing dataset {}\".format(i))\n",
    "        noise_df = df.applymap(add_noise)\n",
    "        scaling_df = df.applymap(scaling)\n",
    "        time_df = df.applymap(time_shift)\n",
    "        lst.append(data_shape(noise_df))\n",
    "        lst.append(data_shape(scaling_df))\n",
    "        lst.append(data_shape(time_df))\n",
    "    \n",
    "    return pd.concat(lst, axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_audio_dataset() :\n",
    "    _df = dataset(paths = original_audio.T, labels = soundfiles)\n",
    "    frames = []\n",
    "    for i in range(len(_df.columns)) :\n",
    "        for j in _df[_df.columns[i]] :\n",
    "            tmp = pd.DataFrame(j.reshape(200,))\n",
    "            tmp = tmp.T\n",
    "            tmp['label'] = i\n",
    "            frames.append(tmp)\n",
    "    _df =  pd.concat(frames, ignore_index = True)\n",
    "    _df.iloc[:, -1] = _df.iloc[:, -1].map(lambda x : int(x))\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aug_audio_df = aug_audio_dataset()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in aug_audio_df.columns :\n",
    "    aug_audio_df[i] /= np.max(aug_audio_df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#aug_audio_df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Creating entire dataset from melspectrograms augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting audiomentations\n",
      "  Downloading audiomentations-0.24.0-py3-none-any.whl (67 kB)\n",
      "Requirement already satisfied: numpy>=1.13.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from audiomentations) (1.19.2)\n",
      "Requirement already satisfied: librosa<0.10.0,>0.7.2 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from audiomentations) (0.8.1)\n",
      "Requirement already satisfied: scipy<2,>=1.0.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from audiomentations) (1.5.2)\n",
      "Requirement already satisfied: audioread>=2.0.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (2.1.9)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (20.4)\n",
      "Requirement already satisfied: soundfile>=0.10.2 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.10.3.post1)\n",
      "Requirement already satisfied: resampy>=0.2.2 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.2.2)\n",
      "Requirement already satisfied: scikit-learn!=0.19.0,>=0.14.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.23.2)\n",
      "Requirement already satisfied: joblib>=0.14 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.17.0)\n",
      "Requirement already satisfied: pooch>=1.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (1.5.1)\n",
      "Requirement already satisfied: decorator>=3.0.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (4.4.2)\n",
      "Requirement already satisfied: numba>=0.43.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from librosa<0.10.0,>0.7.2->audiomentations) (0.51.2)\n",
      "Requirement already satisfied: llvmlite<0.35,>=0.34.0.dev0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (0.34.0)\n",
      "Requirement already satisfied: setuptools in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from numba>=0.43.0->librosa<0.10.0,>0.7.2->audiomentations) (50.3.1.post20201107)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from packaging>=20.0->librosa<0.10.0,>0.7.2->audiomentations) (2.4.7)\n",
      "Requirement already satisfied: six in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from packaging>=20.0->librosa<0.10.0,>0.7.2->audiomentations) (1.15.0)\n",
      "Requirement already satisfied: requests in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.24.0)\n",
      "Requirement already satisfied: appdirs in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.4.4)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from scikit-learn!=0.19.0,>=0.14.0->librosa<0.10.0,>0.7.2->audiomentations) (2.1.0)\n",
      "Requirement already satisfied: cffi>=1.0 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (1.14.3)\n",
      "Requirement already satisfied: pycparser in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from cffi>=1.0->soundfile>=0.10.2->librosa<0.10.0,>0.7.2->audiomentations) (2.20)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (3.0.4)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (1.25.11)\n",
      "Requirement already satisfied: idna<3,>=2.5 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2.10)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\ineed\\anaconda3\\lib\\site-packages (from requests->pooch>=1.0->librosa<0.10.0,>0.7.2->audiomentations) (2021.10.8)\n",
      "Installing collected packages: audiomentations\n",
      "Successfully installed audiomentations-0.24.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install audiomentations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "mel = df.iloc[0,:-1].values.reshape(20,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from audiomentations import SpecCompose, SpecChannelShuffle, SpecFrequencyMask\n",
    "import numpy as np\n",
    "\n",
    "augment = SpecCompose( [SpecFrequencyMask(p=0.5),])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Augment/transform/perturb the spectrogram\n",
    "augmented_spectrogram = augment(mel)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aug_spec_dataset(df) :\n",
    "    _df = df.copy()\n",
    "    frames = []\n",
    "    for i in range(15) :\n",
    "        print(i)\n",
    "        tmp_df = _df.copy()\n",
    "        for j in range(tmp_df.shape[0]) :\n",
    "            print(j)\n",
    "            mel = tmp_df.iloc[j,:-1].values.reshape(20,10)\n",
    "            augment = SpecCompose( [SpecFrequencyMask(p=np.random.random()),])\n",
    "            augmented_spectrogram = augment(mel)\n",
    "            tmp_df.iloc[j, :-1] = augmented_spectrogram.reshape(200,)\n",
    "        frames.append(tmp_df)\n",
    "            \n",
    "    aug_df =  pd.concat(frames)\n",
    "    aug_df.iloc[:, -1] =aug_df.iloc[:, -1].map(lambda x : int(x))\n",
    "    return aug_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec_df = aug_spec_dataset(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in spec_df.columns :\n",
    "    spec_df[i] /= np.max(spec_df[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#spec_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [],
   "source": [
    "spec_df.to_csv(\"spec_dataset.csv\", index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def concat(df1, df2) :\n",
    "    lst = []\n",
    "    for i in range(df1.shape[0]) :\n",
    "        lst.append(list(df1.iloc[i, :].values))\n",
    "    \n",
    "    for i in range(df2.shape[0]) :\n",
    "        lst.append(list(df2.iloc[i, :].values))\n",
    "        \n",
    "    _df = pd.DataFrame(np.array(lst))\n",
    "    return _df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df = concat(spec_df, aug_audio_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df.iloc[:, -1] =final_df.iloc[:, -1].map(lambda x : int(x))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
