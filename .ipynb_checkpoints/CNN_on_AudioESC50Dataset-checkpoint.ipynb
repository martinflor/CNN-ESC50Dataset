{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Librarie's import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import Dataset\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import soundfile as sf\n",
    "from scipy import signal\n",
    "import random\n",
    "import librosa"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Loading OGG files (audio files)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_ogg_file(audio, max_ms = 5000):\n",
    "    # Load encoded wav file\n",
    "    x, fs = audio\n",
    "    # Sampling frequency of the ADC\n",
    "    sr = 10989\n",
    "    M = fs//sr\n",
    "    # Resampling the audio file from 44100 Hz to 10200\n",
    "    sig = signal.resample(x, int(len(x)/M))\n",
    "    \n",
    "    sig_len = len(sig)\n",
    "    max_len = int(sr * max_ms/1000)\n",
    "\n",
    "    if (sig_len > max_len):\n",
    "        sig = sig[:max_len]\n",
    "\n",
    "    elif (sig_len < max_len):\n",
    "        # Length of padding to add at the beginning and end of the signal\n",
    "        pad_begin_len = random.randint(0, max_len - sig_len)\n",
    "        pad_end_len = max_len - sig_len - pad_begin_len\n",
    "\n",
    "        # Pad with 0s\n",
    "        pad_begin = np.zeros(pad_begin_len)\n",
    "        pad_end = np.zeros(pad_end_len)\n",
    "\n",
    "        sig = np.concatenate((pad_begin, sig, pad_end))\n",
    "        \n",
    "    return sig"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Dataframe with audio resampled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "soundfiles = ['203 - Crackling fire', '205 - Chirping birds', '501 - Helicopter', '502 - Chainsaw', '510 - Hand saw' ]\n",
    "original_audio = np.array([[mypath + \"/\" + f for f in listdir(mypath) if isfile(join(mypath, f))] for mypath in [\"Dataset_ESC-50/\" + soundfiles[i] for i in range(len(soundfiles))]])\n",
    "audio_df = pd.DataFrame(data = original_audio.T, columns = soundfiles)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Melspectrograms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def melspectrogram(x, Nft = 512, fs_down = 10447, Nmel = 20) :\n",
    "    \"\"\"\n",
    "    Pre : x is the resampled signal\n",
    "    Post : melspectrogram of x\n",
    "    \"\"\"\n",
    "\n",
    "    L = len(x)\n",
    "    x_crop = x[:L-L%Nft]\n",
    "    x_new = x_crop if len(x.shape)==1 else np.mean(x_crop,axis=1)\n",
    "    L_new = len(x_new)\n",
    "    \n",
    "    audiomat = np.reshape(x_new, (L_new//Nft,Nft))\n",
    "    audioham = audiomat*np.hamming(Nft) # Windowing.\n",
    "    z = np.reshape(audioham,-1) # y windowed by pieces\n",
    "\n",
    "    stft = np.fft.fft(audioham, axis=1)\n",
    "    stft = np.abs(stft[:,:Nft//2].T) # Taking only positive frequencies and computing the magnitude\n",
    "    \n",
    "    mels = librosa.filters.mel(sr=fs_down, n_fft=Nft, n_mels=Nmel)\n",
    "    mels = mels[:,:-1]\n",
    "    mels = mels/np.max(mels)\n",
    "    \n",
    "    melspec = mels@stft\n",
    "    \n",
    "    return melspec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Creating an entire dataset from audio path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 Audio transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_bg(filename1, filename2, amplitude_limit=0.1):\n",
    "    sig1,sr1 = sf.read(filename1)\n",
    "    sig2, sr2 = sf.read(filename2)\n",
    "    sig = sig + sig2[:len(sig)] * np.max(sig)/np.max(sig2) * np.random.uniform(0,amplitude_limit)\n",
    "    return (sig, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scaling(filename, scaling_limit=5):\n",
    "    sig,sr = sf.read(filename)\n",
    "    sig = np.random.uniform(0,scaling_limit)*sig\n",
    "    return (sig, sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_noise(filename, sigma=0.05):\n",
    "    sig,sr = sf.read(filename)\n",
    "    size = len(sig)\n",
    "    random_list = np.random.normal(loc=0.0, scale=sigma, size=size)\n",
    "    return (sig + random_list,sr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.2 Dataset computation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(paths, label, transform = False) :\n",
    "    df = pd.DataFrame(data = paths, columns = label)\n",
    "    df_original = df.applymap(lambda x :  sf.read(x))\n",
    "    df_original = df_original.applymap(load_ogg_file)\n",
    "    df_original = df_original.applymap(melspectrogram)\n",
    "    lst = [df_original]\n",
    "    for i in range(2) :\n",
    "        print(\"computing dataset {}\".format(i))\n",
    "        tmp_df = df.applymap(add_noise)\n",
    "        tmp_df = tmp_df.applymap(load_ogg_file)\n",
    "        lst.append(tmp_df.applymap(melspectrogram))\n",
    "    \n",
    "    return pd.concat(lst, axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset(original_audio.T, soundfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-10-197405b6b7e9>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mframes\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mdf\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m         \u001b[0mtmp\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtmp\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "frames = []\n",
    "for i in range(len(df.columns)) :\n",
    "    for j in df[df.columns[i]] :\n",
    "        tmp = np.append(j,i)\n",
    "        tmp = pd.DataFrame(tmp).T\n",
    "        frames.append(tmp)\n",
    "\n",
    "test_df = pd.concat(frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df.to_csv(\"test_melspec.csv\", index = False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Classification using CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.1 Network definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MelSpecClassifier (nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        conv_layers = []\n",
    "\n",
    "        # First Convolution Block\n",
    "        self.conv1 = nn.Conv2d(1, 8, kernel_size=5, stride=2, padding=2)\n",
    "        self.relu1 = nn.PReLU()\n",
    "        self.bn1 = nn.BatchNorm2d(8)\n",
    "        conv_layers += [self.conv1, self.relu1, self.bn1]\n",
    "        \n",
    "        # Second Convolution Block\n",
    "        self.conv2 = nn.Conv2d(8, 16, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu2 = nn.PReLU()\n",
    "        self.bn2 = nn.BatchNorm2d(16)\n",
    "        conv_layers += [self.conv2, self.relu2, self.bn2]\n",
    "        \n",
    "        # Third Convolution Block\n",
    "        self.conv3 = nn.Conv2d(16, 32, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu3 = nn.PReLU()\n",
    "        self.bn3 = nn.BatchNorm2d(32)\n",
    "        conv_layers += [self.conv3, self.relu3, self.bn3]\n",
    "\n",
    "        # Fourth Convolution Block\n",
    "        self.conv4 = nn.Conv2d(32, 64, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu4 = nn.PReLU()\n",
    "        self.bn4 = nn.BatchNorm2d(64)\n",
    "        conv_layers += [self.conv4, self.relu4, self.bn4]\n",
    "        \n",
    "        # Fifth Convolution Block\n",
    "        self.conv5 = nn.Conv2d(64, 128, kernel_size=3, stride=2, padding=1)\n",
    "        self.relu5 = nn.PReLU()\n",
    "        self.bn5 = nn.BatchNorm2d(128)\n",
    "        conv_layers += [self.conv5, self.relu5, self.bn5]\n",
    "        \n",
    "        \n",
    "        # Dropout Layer\n",
    "        self.drp = nn.Dropout2d(p = 0.2)\n",
    "        \n",
    "        # Linear Classifier\n",
    "        self.ap = nn.AdaptiveAvgPool2d(output_size=1)\n",
    "        self.fc = nn.Linear(in_features=128, out_features=5)\n",
    "\n",
    "        # Wrap the Convolutional Blocks\n",
    "        self.conv = nn.Sequential(*conv_layers)\n",
    "        self.initialize_weights()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv(x)\n",
    "        x = self.drp(x)\n",
    "        # Adaptive pool and flatten for input to linear layer\n",
    "        x = self.ap(x)\n",
    "        x = x.view(x.shape[0], -1)\n",
    "        x = self.fc(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "    def initialize_weights(self) :\n",
    "        for m in self.modules() :\n",
    "            if isinstance(m, nn.Conv2d) :\n",
    "                nn.init.kaiming_normal_(m.weight, a = 0.1)\n",
    "                if m.bias is not None :\n",
    "                    nn.init.constant_(m.bias, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.2 Custom dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self, df):\n",
    "        self.df = df\n",
    "        col = [\"data\", \"label\"]\n",
    "        labels = []\n",
    "        mels = []\n",
    "        for i in range(len(self.df.columns)) :\n",
    "            labels += [i] * len(self.df[self.df.columns[i]])\n",
    "\n",
    "        for i in self.df.columns :\n",
    "            for j in self.df[i].values :\n",
    "                mels.append(j)\n",
    "        row = [mels, labels]      \n",
    "        dic = {col[i]: row[i] for i in range(len(col))}\n",
    "        self.data = pd.DataFrame.from_dict(dic)\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)    \n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        specgram = torch.Tensor(self.data[\"data\"][idx]).unsqueeze(0)\n",
    "        class_label = torch.tensor(self.data[\"label\"][idx])\n",
    "        return specgram, class_label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.3 Dataset matching specifications\n",
    "- ADC samples the signal received from the microphone at a 10989 Hz\n",
    "- 20 melvectors are computed with ONLY 10 components (here we have 102)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def shaping_audio(audio, dic, col, nb = 10, sr=10989) :\n",
    "    sig = load_ogg_file(audio)\n",
    "    sig_len = sig.shape[0]\n",
    "    L = sig_len//nb\n",
    "    for i in range(nb) :\n",
    "        mels = melspectrogram(sig[i*L:(i+1)*L])\n",
    "        dic[col].append(mels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def data_shape(_df) :\n",
    "    dic = {}\n",
    "    for i in _df.columns :\n",
    "        print(i)\n",
    "        dic[i] = []\n",
    "        for j in _df[i].values :\n",
    "            shaping_audio(sf.read(j), dic, i)\n",
    "    return pd.DataFrame.from_dict(dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset(paths, label, transform = False) :\n",
    "    df = pd.DataFrame(data = paths, columns = label) # sound paths\n",
    "    df_original = df.applymap(lambda x :  sf.read(x)) # sounds\n",
    "    df_original = df_original.applymap(shaping_audio) # shaping sounds\n",
    "    \n",
    "    lst = [df_original]\n",
    "    for i in range(2) :\n",
    "        print(\"computing dataset {}\".format(i))\n",
    "        tmp_df = df.applymap(add_noise)\n",
    "        lst.append(tmp_df.applymap(shaping_audio))\n",
    "    \n",
    "    return pd.concat(lst, axis = 0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "203 - Crackling fire\n",
      "205 - Chirping birds\n",
      "501 - Helicopter\n",
      "502 - Chainsaw\n",
      "510 - Hand saw\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>203 - Crackling fire</th>\n",
       "      <th>205 - Chirping birds</th>\n",
       "      <th>501 - Helicopter</th>\n",
       "      <th>502 - Chainsaw</th>\n",
       "      <th>510 - Hand saw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[[0.16139553802987835, 1.129010422569741, 0.41...</td>\n",
       "      <td>[[0.28009388384273526, 0.19227444108293093, 0....</td>\n",
       "      <td>[[34.67986352239215, 55.242985228413545, 47.20...</td>\n",
       "      <td>[[4.106173216198236, 9.108093557076055, 6.5726...</td>\n",
       "      <td>[[0.6273128829696692, 0.3741801137366557, 2.05...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[[4.178506481438082, 3.2839335317721763, 3.164...</td>\n",
       "      <td>[[0.38288912788831536, 0.17849659969166626, 0....</td>\n",
       "      <td>[[43.82066243073142, 51.58700410348674, 52.876...</td>\n",
       "      <td>[[3.789552204883522, 3.773905988869249, 13.803...</td>\n",
       "      <td>[[1.2567006914069319, 1.993477808757619, 3.545...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[[4.072953643684883, 4.534967315838344, 3.7293...</td>\n",
       "      <td>[[0.1901116309065296, 0.1345662833831983, 0.18...</td>\n",
       "      <td>[[70.6355997509764, 37.32341964246812, 42.4516...</td>\n",
       "      <td>[[15.123331135589117, 16.98377124720216, 13.71...</td>\n",
       "      <td>[[4.166573230657808, 2.95486542373388, 4.55522...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[[6.399588357633699, 5.285834362321213, 22.364...</td>\n",
       "      <td>[[0.231994821830621, 0.13810245794547907, 0.12...</td>\n",
       "      <td>[[48.29891257472128, 84.53330462761731, 46.911...</td>\n",
       "      <td>[[11.05480935856629, 19.522449101939, 28.22597...</td>\n",
       "      <td>[[5.2499992535204205, 3.4750105349216263, 2.33...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[[3.368813194857822, 6.33667596082666, 2.12766...</td>\n",
       "      <td>[[0.1251758583537867, 0.14452445143416476, 0.1...</td>\n",
       "      <td>[[64.42056927763981, 53.373142348067645, 47.18...</td>\n",
       "      <td>[[18.796135817532075, 34.5725488736344, 35.818...</td>\n",
       "      <td>[[7.687703889976566, 3.5899370107809023, 4.947...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                203 - Crackling fire  \\\n",
       "0  [[0.16139553802987835, 1.129010422569741, 0.41...   \n",
       "1  [[4.178506481438082, 3.2839335317721763, 3.164...   \n",
       "2  [[4.072953643684883, 4.534967315838344, 3.7293...   \n",
       "3  [[6.399588357633699, 5.285834362321213, 22.364...   \n",
       "4  [[3.368813194857822, 6.33667596082666, 2.12766...   \n",
       "\n",
       "                                205 - Chirping birds  \\\n",
       "0  [[0.28009388384273526, 0.19227444108293093, 0....   \n",
       "1  [[0.38288912788831536, 0.17849659969166626, 0....   \n",
       "2  [[0.1901116309065296, 0.1345662833831983, 0.18...   \n",
       "3  [[0.231994821830621, 0.13810245794547907, 0.12...   \n",
       "4  [[0.1251758583537867, 0.14452445143416476, 0.1...   \n",
       "\n",
       "                                    501 - Helicopter  \\\n",
       "0  [[34.67986352239215, 55.242985228413545, 47.20...   \n",
       "1  [[43.82066243073142, 51.58700410348674, 52.876...   \n",
       "2  [[70.6355997509764, 37.32341964246812, 42.4516...   \n",
       "3  [[48.29891257472128, 84.53330462761731, 46.911...   \n",
       "4  [[64.42056927763981, 53.373142348067645, 47.18...   \n",
       "\n",
       "                                      502 - Chainsaw  \\\n",
       "0  [[4.106173216198236, 9.108093557076055, 6.5726...   \n",
       "1  [[3.789552204883522, 3.773905988869249, 13.803...   \n",
       "2  [[15.123331135589117, 16.98377124720216, 13.71...   \n",
       "3  [[11.05480935856629, 19.522449101939, 28.22597...   \n",
       "4  [[18.796135817532075, 34.5725488736344, 35.818...   \n",
       "\n",
       "                                      510 - Hand saw  \n",
       "0  [[0.6273128829696692, 0.3741801137366557, 2.05...  \n",
       "1  [[1.2567006914069319, 1.993477808757619, 3.545...  \n",
       "2  [[4.166573230657808, 2.95486542373388, 4.55522...  \n",
       "3  [[5.2499992535204205, 3.4750105349216263, 2.33...  \n",
       "4  [[7.687703889976566, 3.5899370107809023, 4.947...  "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audio_df = pd.DataFrame(data = original_audio.T, columns = soundfiles)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(20, 10)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aug_df[\"203 - Crackling fire\"][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.4 Fitting data, inference and loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 312,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inference (model, val_dl):\n",
    "    correct_prediction = 0\n",
    "    total_prediction = 0\n",
    "\n",
    "    # Disable gradient updates\n",
    "    with torch.no_grad():\n",
    "        for data in val_dl:\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "\n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Get predictions\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "            acc = correct_prediction/total_prediction\n",
    "            print(f'Test Accuracy: {acc:.2f}, Total items: {total_prediction}')\n",
    "\n",
    "    return acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "metadata": {},
   "outputs": [],
   "source": [
    "def training(model, train_dl, num_epochs):\n",
    "    acc_train = []\n",
    "    acc_test = []\n",
    "\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        correct_prediction = 0\n",
    "        total_prediction = 0\n",
    "\n",
    "        # Repeat for each batch in the training set\n",
    "        for i, data in enumerate(train_dl):\n",
    "            # Get the input features and target labels, and put them on the GPU\n",
    "            inputs, labels = data[0].to(device), data[1].to(device)\n",
    "            \n",
    "            # Normalize the inputs\n",
    "            inputs_m, inputs_s = inputs.mean(), inputs.std()\n",
    "            inputs = (inputs - inputs_m) / inputs_s\n",
    "\n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # forward + backward + optimize\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            # Keep stats for Loss and Accuracy\n",
    "            running_loss += loss.item()\n",
    "\n",
    "            # Get the predicted class with the highest score\n",
    "            _, prediction = torch.max(outputs,1)\n",
    "            # Count of predictions that matched the target label\n",
    "            correct_prediction += (prediction == labels).sum().item()\n",
    "            total_prediction += prediction.shape[0]\n",
    "\n",
    "            #if i % 10 == 0:    # print every 10 mini-batches\n",
    "            #    print('[%d, %5d] loss: %.3f' % (epoch + 1, i + 1, running_loss / 10))\n",
    "\n",
    "        # Print stats at the end of the epoch\n",
    "        num_batches = len(train_dl)\n",
    "        avg_loss = running_loss / num_batches\n",
    "        acc = correct_prediction/total_prediction\n",
    "        acc_train.append(acc)\n",
    "        print(f'Epoch: {epoch}, Loss: {avg_loss:.2f}, Train Accuracy: {acc:.2f}')\n",
    "\n",
    "        acc_test.append(inference(model, val_dl))\n",
    "\n",
    "\n",
    "    print('Finished Training')\n",
    "    return acc_train, acc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.5 Dataset and dataloaders initializations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 380,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import random_split\n",
    "myds = CustomDataset(aug_df)\n",
    "\n",
    "num_items = len(myds)\n",
    "num_train = round(num_items * 0.8)\n",
    "num_val = num_items - num_train\n",
    "train_ds, val_ds = random_split(myds, [num_train, num_val])\n",
    "\n",
    "train_dl = torch.utils.data.DataLoader(train_ds, batch_size=64, shuffle=True)\n",
    "val_dl = torch.utils.data.DataLoader(val_ds, batch_size=16, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6.6 Training and validation steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 381,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0, Loss: 1.69, Train Accuracy: 0.39\n",
      "Test Accuracy: 0.44, Total items: 16\n",
      "Test Accuracy: 0.41, Total items: 32\n",
      "Test Accuracy: 0.35, Total items: 48\n",
      "Test Accuracy: 0.38, Total items: 64\n",
      "Test Accuracy: 0.41, Total items: 80\n",
      "Epoch: 1, Loss: 1.25, Train Accuracy: 0.75\n",
      "Test Accuracy: 0.94, Total items: 16\n",
      "Test Accuracy: 0.88, Total items: 32\n",
      "Test Accuracy: 0.88, Total items: 48\n",
      "Test Accuracy: 0.86, Total items: 64\n",
      "Test Accuracy: 0.85, Total items: 80\n",
      "Epoch: 2, Loss: 0.80, Train Accuracy: 0.97\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 0.98, Total items: 48\n",
      "Test Accuracy: 0.98, Total items: 64\n",
      "Test Accuracy: 0.99, Total items: 80\n",
      "Epoch: 3, Loss: 0.32, Train Accuracy: 0.98\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 4, Loss: 0.10, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 5, Loss: 0.02, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 6, Loss: 0.01, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 7, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 8, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 9, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 10, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 11, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 12, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 13, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 14, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 15, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 16, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 17, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 18, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Epoch: 19, Loss: 0.00, Train Accuracy: 1.00\n",
      "Test Accuracy: 1.00, Total items: 16\n",
      "Test Accuracy: 1.00, Total items: 32\n",
      "Test Accuracy: 1.00, Total items: 48\n",
      "Test Accuracy: 1.00, Total items: 64\n",
      "Test Accuracy: 1.00, Total items: 80\n",
      "Finished Training\n",
      "Time needed :  2.042079210281372\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "# Model Instantiation\n",
    "myModel = MelSpecClassifier()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "myModel = myModel.to(device)\n",
    "next(myModel.parameters()).device\n",
    "\n",
    "# Training and validation step\n",
    "t_init = time.time()\n",
    "num_epochs= 20\n",
    "trainAcc, testAcc = training(myModel, train_dl, num_epochs)\n",
    "t_final= time.time()\n",
    "print(\"Time needed : \", t_final-t_init)\n",
    "\n",
    "# Plotting curve of train/test accuracies with regards to the number of epochs\n",
    "x = np.arange(0, num_epochs, 1)\n",
    "\n",
    "plt.plot(x, trainAcc, label = 'train')\n",
    "plt.plot(x, testAcc, label = 'test')\n",
    "plt.grid()\n",
    "plt.legend()\n",
    "plt.xlabel(\"Number of Epochs\")\n",
    "plt.ylabel(\"Train/Test accuracy\")\n",
    "plt.title(\"Train/Test accuracy with regards to the number of epochs\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
